<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>CompRobo2020</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<!-- <a href="index.html" class="logo">
									<span class="symbol"><img src="images/logo.svg" alt="" /></span><span class="title">Phantom</span>
								</a> -->

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

					<!-- Menu -->
						<nav id="menu">
							<h2>Menu</h2>
							<ul>
								<li><a href="index.html">Home</a></li>
								<li><a href="implementation.html">Implementation</a></li>
								<li><a href="blog.html">Project Story</a></li>
							</ul>
						</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Implementation</h1>
								<h2>Description and Goals</h2>
								For the final Computational Robotics Project, our team decided to built off of our computer vision project and implemnted simulated sign recogntion.
								<ul>
							  <li>Create a custom gazebo world containing road signs from the selected dataset/li>
							  <li>Use the simulated neato camera feed to extract the potential signs </li>
							  <li>Use a CNN to identify what type of road sign it is</li>
								<li>Have the neato respond to the type of road sign with the appropriate behavior </li>
								</ul>
								<span class="image main"><img src="images/3_signs_in_a_row.gif" alt="" style="width:800px"/></span>
								<h1>System Architecture</h1>
								Our SignDetection class includes instances of 3 other classes, RobotMotion, ImageExtractor, and PredictCNN. PredictCNN relies on a pre-trained and saved
								convultional neural net. Within SignDetection, ImageExtractor find a region of interest (ROI), PredictCNN classifies it, and RobotMotion controls the behavior of a simulated neato.
								For the simulated neato to have a place to navigate and bring in camera feed from, we designed a Gazebo world with a
								handful of road signs for the neato to react to.

								<span class="image main"><img src="images/sign_detection_diagram.png" alt="" style="width:700px"/></span>
								<h2> Gazebo World</h2>
								<h2> Image Extraction</h2>
								To identify the region of the video that is most likely to

								<ol>
							  <li>Crop the video to elimate the bottom 3rd of the camera feed.
								<li> Convert it to grayscale.
							  <li> Apply an adaptive filter using OpenCVs <code>adaptiveThreshold</code> to generate a binary feed.
							  <li> Generate contours from the binary feed.
								<li>From each contour object, approximate the area and number of vertices.
								<li> Filter out contours with areas > 20000 and < 1000. This elimates noise from tiny contours and also ignores any contours that are the full perimeter of the camera feed.
								<li> For the remainging contours, any shapes with more than 4 vertices is considered a potential sign.
								<li>Finally, the largest remaining contour is considered the ROI (region of interest) for that frame in the video feed and is saved.
								</ol>

								As the simulated camera comes, a binary threshold and contour feed are generated. From
								each frame, a boudning box is placed around the ROI where a sign is suspected of being.
								<br>
								<br>
								<span class="image main"><img src="images/threshold_contours.gif" alt="" style="width:600px"/></span>
								<br>
								<br>
								<h2> Sign Classifier (CNN)</h2>
								To classify the region of interest image found duing image extraction, we built off of a simple convolutional neural net that we built during the prior
								<a href="https://github.com/vscheyer/computer_vision">computer vision project</a>.
								<br>
								<br>
								Our classifier was trained on the publicly available portion of the Chinese Traffic Sign Recognition database [1]
								<br>
								<br>
								[1] https://www.kaggle.com/dmitryyemelyanov/chinese-traffic-signs
								The dataset is a converted version of publicly available Chinese Traffic Sign Recognition Database. This work is supported by National Nature Science Foundation of China(NSFC) Grant 61271306
								Credits:
								LinLin Huang,Prof.Ph.D
								School of Electronic and Information Engingeering,
								Beijing Jiaotong University,
								Beijing 100044,China
								Email: huangll@bjtu.edu.cn
								All images originally collected by camera under nature scenes or from BAIDU Street View


						</div>
					</div>

					<!-- Footer -->
						<footer id="footer">
							<div class="inner">

								<section>
									<ul class="icons">
										<li><a href="#" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
									</ul>
								</section>
								<ul class="copyright">
									<li>&copy; Abby Fry & Vienna Scheyer 2020</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
								</ul>
							</div>
						</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
